{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(actual, pred):\n",
    "    \"\"\"Computes the R value of the predictions given the actual values.\n",
    "    \n",
    "    Both actual and pred should be of the same length where each index\n",
    "    corresponds to the actual and predicted value of the same row of data.\n",
    "    \n",
    "    Args:\n",
    "        actual: A list of actual values.\n",
    "        pred: A list of predicted values.\n",
    "    \n",
    "    Returns:\n",
    "        R value of the predictions given the actual values.\n",
    "    \"\"\"\n",
    "    assert len(actual) == len(pred)\n",
    "    nume = np.sum(np.square(actual - pred))\n",
    "    denom = np.sum(np.square(actual - np.mean(actual)))\n",
    "    r_sq = 1 - nume / denom\n",
    "    return np.sign(r_sq) * np.sqrt(np.abs(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \"\"\"A generic Model interface to encapsulate modeling and data processing.\n",
    "    \n",
    "    Attributes:\n",
    "        model_: A sklearn model with two function interfaces - fit, predict.\n",
    "        columns_: List of column names corresponding to the features.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        \"\"\"Initialize the Model class with the given model.\n",
    "        \n",
    "        Args:\n",
    "            model: A sklearn model.\n",
    "        \"\"\"\n",
    "        self.model_ = model\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \"\"\"Fit the underlying model with the given data frame.\n",
    "        \n",
    "        Args:\n",
    "            df: Dataframe object containing the underlying data. It has three\n",
    "                special columns - id, y (label), timestamp.\n",
    "        \"\"\"\n",
    "        # Sets the NaN values as 0 and drops the two special columns.\n",
    "        X_train = df.drop(['id', 'y', 'timestamp'], axis=1).fillna(0)\n",
    "        Y_train = df['y']\n",
    "        self.model_.fit(X_train, Y_train)\n",
    "        self.columns_ = X_train.columns\n",
    "    \n",
    "    def predict(self, df):\n",
    "        \"\"\"Infers the predictions for the given df features.\n",
    "        \n",
    "        Args:\n",
    "            df: Dataframe object containing the data features to be predicted. It has\n",
    "                two special columns - id, timestamp.\n",
    "        \n",
    "        Returns:\n",
    "            The predictions for each of the row in df, in the same order as given.\n",
    "        \"\"\"\n",
    "        return self.model_.predict(df.drop(['id', 'timestamp'], axis=1).fillna(0))\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize the underlying learned model.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LinearRegressionModel(Model):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__(LinearRegression())\n",
    "    \n",
    "    def visualize(self):\n",
    "        assert len(self.columns_) == len(self.model_.coef_), \\\n",
    "            \"# columns: %d vs # coeff: %d\" % (len(self.columns_), len(self.model_.coef_))\n",
    "        print('Bias: ', self.model_.intercept_)\n",
    "        for (ind, column) in enumerate(self.columns_):\n",
    "            print(column, ': ', self.model_.coef_[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_df):\n",
    "    \"\"\"Returns a new model trained using the given data frame.\n",
    "\n",
    "    Args:\n",
    "        train_df: DataFrame object corresponding to training data.\n",
    "    \n",
    "    Returns:\n",
    "        Model trained using the data frame.\n",
    "    \"\"\"\n",
    "    model = LinearRegressionModel()\n",
    "    model.fit(train_df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_infer(model, features, target):\n",
    "    \"\"\"Populates the target using the features and model and updates the\n",
    "    model.\n",
    "    \n",
    "    Args:\n",
    "        model: A model for prediction and then for updating with new data.\n",
    "        features: DataFrame object corresponding to new data to predict\n",
    "                  on, and then update the existing model.\n",
    "        target: DataFrame object containing id and the y value to be updated\n",
    "                with.\n",
    "    \"\"\"\n",
    "    # Verify that the features and targets are aligned.\n",
    "    assert len(features) == len(target)\n",
    "    assert (features['id'] == target['id']).all()\n",
    "\n",
    "    # Set the target value to the one given.\n",
    "    target['y'] = model.predict(features)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  0.000255509309195\n",
      "derived_0 :  -3.79935403107e-27\n",
      "derived_1 :  -9.33099228834e-19\n",
      "derived_2 :  7.75481824268e-25\n",
      "derived_3 :  0.0\n",
      "derived_4 :  1.51886650068e-25\n",
      "fundamental_0 :  -6.5455437499e-31\n",
      "fundamental_1 :  1.59284585172e-23\n",
      "fundamental_2 :  -4.97555725652e-30\n",
      "fundamental_3 :  -6.39797066095e-32\n",
      "fundamental_5 :  1.40149668146e-30\n",
      "fundamental_6 :  -9.1477904899e-32\n",
      "fundamental_7 :  -2.83456009951e-28\n",
      "fundamental_8 :  -2.3649933944e-32\n",
      "fundamental_9 :  -8.28133242841e-32\n",
      "fundamental_10 :  3.63901500746e-31\n",
      "fundamental_11 :  -8.84056011253e-30\n",
      "fundamental_12 :  8.1227256981e-29\n",
      "fundamental_13 :  7.38967705777e-31\n",
      "fundamental_14 :  -3.36369442577e-29\n",
      "fundamental_15 :  1.28694739008e-30\n",
      "fundamental_16 :  -1.20542281315e-30\n",
      "fundamental_17 :  4.46917566637e-21\n",
      "fundamental_18 :  -8.83249076699e-30\n",
      "fundamental_19 :  5.48561554009e-31\n",
      "fundamental_20 :  1.06912396106e-29\n",
      "fundamental_21 :  6.13253427993e-31\n",
      "fundamental_22 :  -6.84617313874e-31\n",
      "fundamental_23 :  -1.38538640913e-28\n",
      "fundamental_24 :  -1.89904321475e-31\n",
      "fundamental_25 :  -1.01832210448e-30\n",
      "fundamental_26 :  -8.19091457186e-28\n",
      "fundamental_27 :  -1.1564602949e-29\n",
      "fundamental_28 :  -5.75272417937e-32\n",
      "fundamental_29 :  2.04292435806e-30\n",
      "fundamental_30 :  2.75606593573e-30\n",
      "fundamental_31 :  -9.34917618208e-32\n",
      "fundamental_32 :  -3.67927459812e-29\n",
      "fundamental_33 :  -3.67904311338e-27\n",
      "fundamental_34 :  -3.76178768116e-30\n",
      "fundamental_35 :  -9.98779651956e-31\n",
      "fundamental_36 :  -1.59638359012e-28\n",
      "fundamental_37 :  -6.86756055315e-31\n",
      "fundamental_38 :  5.80438127862e-32\n",
      "fundamental_39 :  -3.29331434403e-31\n",
      "fundamental_40 :  -6.29297844427e-31\n",
      "fundamental_41 :  -9.99015068153e-27\n",
      "fundamental_42 :  -1.19879555611e-26\n",
      "fundamental_43 :  5.51320721369e-31\n",
      "fundamental_44 :  7.03481318077e-31\n",
      "fundamental_45 :  -1.13209020933e-29\n",
      "fundamental_46 :  3.47196421222e-32\n",
      "fundamental_47 :  -1.02789175697e-30\n",
      "fundamental_48 :  -3.92377794971e-30\n",
      "fundamental_49 :  -1.43940435243e-31\n",
      "fundamental_50 :  -6.08714473789e-29\n",
      "fundamental_51 :  -1.15866268231e-30\n",
      "fundamental_52 :  -9.67908255077e-31\n",
      "fundamental_53 :  -1.62466842171e-30\n",
      "fundamental_54 :  4.80626161972e-31\n",
      "fundamental_55 :  -3.03184575015e-30\n",
      "fundamental_56 :  -1.95325181852e-30\n",
      "fundamental_57 :  -1.8154037354e-31\n",
      "fundamental_58 :  -7.85037539315e-31\n",
      "fundamental_59 :  8.51020858413e-31\n",
      "fundamental_60 :  2.61485426956e-30\n",
      "fundamental_61 :  -2.62673756144e-20\n",
      "fundamental_62 :  -4.27207184772e-31\n",
      "fundamental_63 :  -3.59799542679e-31\n",
      "technical_0 :  -2.85586558244e-32\n",
      "technical_1 :  -2.08036947787e-32\n",
      "technical_2 :  6.43516212672e-32\n",
      "technical_3 :  5.01042065573e-32\n",
      "technical_5 :  1.20013024388e-31\n",
      "technical_6 :  -2.76192930155e-31\n",
      "technical_7 :  1.39434318708e-30\n",
      "technical_9 :  8.34066550577e-32\n",
      "technical_10 :  1.0336826183e-30\n",
      "technical_11 :  -4.86440815308e-31\n",
      "technical_12 :  3.73849544868e-31\n",
      "technical_13 :  -3.0638876841e-34\n",
      "technical_14 :  -1.41218107876e-30\n",
      "technical_16 :  -3.87366765997e-32\n",
      "technical_17 :  -8.85960500181e-31\n",
      "technical_18 :  1.1339657811e-31\n",
      "technical_19 :  2.43467190938e-31\n",
      "technical_20 :  6.44877523292e-33\n",
      "technical_21 :  -6.16056746921e-31\n",
      "technical_22 :  1.68115290009e-30\n",
      "technical_24 :  2.32512738512e-32\n",
      "technical_25 :  -1.12941993139e-33\n",
      "technical_27 :  6.4651822541e-31\n",
      "technical_28 :  -3.43715870612e-32\n",
      "technical_29 :  -2.76460359822e-30\n",
      "technical_30 :  3.99505934528e-33\n",
      "technical_31 :  5.09425221085e-32\n",
      "technical_32 :  6.91001482468e-32\n",
      "technical_33 :  3.84411602586e-32\n",
      "technical_34 :  -1.13223267925e-30\n",
      "technical_35 :  -6.97088015892e-32\n",
      "technical_36 :  1.61168727302e-31\n",
      "technical_37 :  -5.50607078749e-32\n",
      "technical_38 :  2.13909126878e-31\n",
      "technical_39 :  1.34620116859e-31\n",
      "technical_40 :  2.50957958159e-31\n",
      "technical_41 :  1.35544031909e-31\n",
      "technical_42 :  -3.2979343307e-32\n",
      "technical_43 :  -4.68062713449e-31\n",
      "technical_44 :  -5.18483874426e-32\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# A cell to perform local E2E training and prediction that simulates\n",
    "# the KaggleGym behavior.\n",
    "def localE2E(run_validation=True, visualize_model=False):\n",
    "    \"\"\"A function to simulate KaggleGym behavior of predicting per timestep.\n",
    "    \"\"\"\n",
    "    # Here's an example of loading the CSV using Pandas's built-in HDF5 support:\n",
    "    with pd.HDFStore(\"train.h5\", \"r\") as train:\n",
    "        # Note that the \"train\" dataframe is the only dataframe in the file\n",
    "        df = train.get(\"train\")\n",
    "        train_df = df[:806298]\n",
    "        valid_df = df[806298:]\n",
    "    \n",
    "    # NOTE: Training goes here.\n",
    "    model = train_model(train_df)\n",
    "    if visualize_model:\n",
    "        model.visualize()\n",
    "    \n",
    "    if not run_validation:\n",
    "        return 0\n",
    "    \n",
    "    # Validation goes here.\n",
    "    predictions = []\n",
    "    curr_timestamp = 0\n",
    "    curr_data = []\n",
    "    curr_target = []\n",
    "    for row in valid_df.itertuples():\n",
    "        # If it is a new timestamp, predict.\n",
    "        if row.timestamp != curr_timestamp:\n",
    "            if curr_data:\n",
    "                # NOTE: Inference and updating goes here.\n",
    "                new_targets = run_infer(\n",
    "                    model,\n",
    "                    # Drop the last column (y).\n",
    "                    pd.DataFrame(curr_data, columns=valid_df.columns[:-1]),\n",
    "                    pd.DataFrame(curr_target, columns=['id', 'y']))\n",
    "                predictions.extend(list(new_targets['y']))\n",
    "            # Reset arrays.\n",
    "            curr_data = []\n",
    "            curr_target= []\n",
    "            curr_timestamp = row.timestamp\n",
    "        # Drop the first (index) and last (y) into features.\n",
    "        curr_data.append(list(row)[1:-1])\n",
    "        curr_target.append([row.id, 0])\n",
    "\n",
    "    # Infer for the last timestamp.\n",
    "    new_targets = run_infer(\n",
    "        model,\n",
    "        # Drop the last column (y).\n",
    "        pd.DataFrame(curr_data, columns=valid_df.columns[:-1]),\n",
    "        pd.DataFrame(curr_target, columns=['id', 'y']))\n",
    "\n",
    "    predictions.extend(list(new_targets['y']))\n",
    "    return evaluate(valid_df['y'], predictions)\n",
    "\n",
    "print(localE2E(run_validation=False, visualize_model=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep track of overall accuracy for each trials.\n",
    "\n",
    "<pre>\n",
    "\n",
    "|R value   | Model              |  Normalization | Features | Use Id | Online update |\n",
    "|----------|--------------------|----------------|----------|--------|----------------\n",
    "|-0.008351 | Always set to 0    |                |          |        |               |\n",
    "|-0.005666 | Linear regression  |  None          | All      |   No   |     No        |\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Linear regression without any normalization, the coefficient for each feature is very low (around e^-20 - e^-30), probably because the features are not normalized and thus too high. It also seems like one of the weight (derived_3) is 0. Hypothesis is that derived_features is computed from fundamental features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data from Kagglegym\n",
    "import kagglegym\n",
    "\n",
    "def kaggleE2E():\n",
    "    \"\"\"Runs Kaggle training and predictions E2E.\n",
    "    \"\"\"\n",
    "    # Create env.\n",
    "    env = kagglegym.make()\n",
    "    # Get first observation.\n",
    "    observation = env.reset()\n",
    "    # Get train data.\n",
    "    train_df = observation.train\n",
    "    model = train_model(train_df)\n",
    "\n",
    "    # Predict using Kagglegym.\n",
    "    while True:\n",
    "        predictions = run_infer(model, observation.features, observation.target)\n",
    "        observation, reward, done, info = env.step(predictions)\n",
    "        # print('Reward: ', reward)\n",
    "        if done:\n",
    "            break\n",
    "    print(info)\n",
    "\n",
    "kaggleE2E()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
