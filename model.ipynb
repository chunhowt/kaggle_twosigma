{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.preprocessing import Imputer, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(actual, pred):\n",
    "    \"\"\"Computes the R value of the predictions given the actual values.\n",
    "    \n",
    "    Both actual and pred should be of the same length where each index\n",
    "    corresponds to the actual and predicted value of the same row of data.\n",
    "    \n",
    "    Args:\n",
    "        actual: A list of actual values.\n",
    "        pred: A list of predicted values.\n",
    "    \n",
    "    Returns:\n",
    "        R value of the predictions given the actual values.\n",
    "    \"\"\"\n",
    "    assert len(actual) == len(pred)\n",
    "    nume = np.sum(np.square(actual - pred))\n",
    "    denom = np.sum(np.square(actual - np.mean(actual)))\n",
    "    r_sq = 1 - nume / denom\n",
    "    return np.sign(r_sq) * np.sqrt(np.abs(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \"\"\"A generic Model interface to encapsulate modeling and data processing.\n",
    "    \n",
    "    Attributes:\n",
    "        model_: A sklearn model with two function interfaces - fit, predict.\n",
    "        imputer_: A sklearn preprocessing model to perform imputation for missing values.\n",
    "        normalizer_: A sklearn preprocessing model to normalize feature values.\n",
    "        columns_: List of column names corresponding to the features.\n",
    "    \"\"\"\n",
    "    def __init__(self, model=None, imputer=None, normalizer=None):\n",
    "        \"\"\"Initialize the Model class with the given model.\n",
    "        \n",
    "        Args:\n",
    "            model: A sklearn model.\n",
    "            imputer: Transformer for missing values.\n",
    "            normalizer: Normalizer for the feature values.\n",
    "        \"\"\"\n",
    "        self.model_ = model\n",
    "        self.imputer_ = imputer\n",
    "        self.normalizer_ = normalizer\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \"\"\"Fit the underlying model with the given data frame.\n",
    "        \n",
    "        Args:\n",
    "            df: Dataframe object containing the underlying data. It has three\n",
    "                special columns - id, y (label), timestamp.\n",
    "        \"\"\"\n",
    "        # Drops the three special columns.\n",
    "        X_train = df.drop(['id', 'y', 'timestamp'], axis=1)\n",
    "        self.columns_ = X_train.columns\n",
    "        \n",
    "        # Imputes the missing value.\n",
    "        if self.imputer_:\n",
    "            X_train = self.imputer_.fit_transform(X_train)\n",
    "        else:\n",
    "            # Fill with 0 if there is no imputer.\n",
    "            X_train = X_train.fillna(0)\n",
    "        \n",
    "        # Normalizes the feature values.\n",
    "        if self.normalizer_:\n",
    "            X_train = self.normalizer_.fit_transform(X_train)\n",
    "        \n",
    "        Y_train = df['y']\n",
    "        self.model_.fit(X_train, Y_train)\n",
    "    \n",
    "    def predict(self, df):\n",
    "        \"\"\"Infers the predictions for the given df features.\n",
    "        \n",
    "        Args:\n",
    "            df: Dataframe object containing the data features to be predicted. It has\n",
    "                two special columns - id, timestamp.\n",
    "        \n",
    "        Returns:\n",
    "            The predictions for each of the row in df, in the same order as given.\n",
    "        \"\"\"\n",
    "        X_pred = df.drop(['id', 'timestamp'], axis=1)\n",
    "        \n",
    "        # Imputes the missing value.\n",
    "        if self.imputer_:\n",
    "            X_pred = self.imputer_.transform(X_pred)\n",
    "        else:\n",
    "            # Fill with 0 if there is no imputer.\n",
    "            X_pred = X_pred.fillna(0)\n",
    "        \n",
    "        # Normalizes the feature values.\n",
    "        if self.normalizer_:\n",
    "            X_pred = self.normalizer_.transform(X_pred)\n",
    "        \n",
    "        return self.model_.predict(X_pred)\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize the underlying learned model.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LinearModel(Model):\n",
    "    \"\"\"Wrapper around sklearn.linear_model.\n",
    "    \"\"\"\n",
    "    def visualize(self):\n",
    "        assert len(self.columns_) == len(self.model_.coef_), \\\n",
    "            \"# columns: %d vs # coeff: %d\" % (len(self.columns_), len(self.model_.coef_))\n",
    "        print('Bias: ', self.model_.intercept_)\n",
    "        for (ind, column) in enumerate(self.columns_):\n",
    "            print(column, ': ', self.model_.coef_[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_df):\n",
    "    \"\"\"Returns a new model trained using the given data frame.\n",
    "\n",
    "    Args:\n",
    "        train_df: DataFrame object corresponding to training data.\n",
    "    \n",
    "    Returns:\n",
    "        Model trained using the data frame.\n",
    "    \"\"\"\n",
    "    model = LinearModel(\n",
    "        model=LinearRegression(),\n",
    "        imputer=Imputer(strategy='median'),\n",
    "        normalizer=RobustScaler())\n",
    "    model.fit(train_df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_infer(model, features, target):\n",
    "    \"\"\"Populates the target using the features and model and updates the\n",
    "    model.\n",
    "    \n",
    "    Args:\n",
    "        model: A model for prediction and then for updating with new data.\n",
    "        features: DataFrame object corresponding to new data to predict\n",
    "                  on, and then update the existing model.\n",
    "        target: DataFrame object containing id and the y value to be updated\n",
    "                with.\n",
    "    \"\"\"\n",
    "    # Verify that the features and targets are aligned.\n",
    "    assert len(features) == len(target)\n",
    "    assert (features['id'] == target['id']).all()\n",
    "\n",
    "    # Set the target value to the one given.\n",
    "    target['y'] = model.predict(features)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  0.00024932422384\n",
      "derived_0 :  1.24728870099e-59\n",
      "derived_1 :  0.0\n",
      "derived_2 :  9.81129486803e-77\n",
      "derived_3 :  -2.14049726543e-76\n",
      "derived_4 :  -2.85539287609e-71\n",
      "fundamental_0 :  4.94684807344e-77\n",
      "fundamental_1 :  -6.47728069998e-67\n",
      "fundamental_2 :  4.62102330091e-76\n",
      "fundamental_3 :  2.50318867411e-77\n",
      "fundamental_5 :  -3.3155452102e-77\n",
      "fundamental_6 :  1.33367145396e-76\n",
      "fundamental_7 :  2.41974940588e-74\n",
      "fundamental_8 :  -3.41603944235e-78\n",
      "fundamental_9 :  5.24742428328e-77\n",
      "fundamental_10 :  -5.39733151988e-77\n",
      "fundamental_11 :  8.09948403311e-76\n",
      "fundamental_12 :  -1.91109606675e-74\n",
      "fundamental_13 :  -8.92350385487e-77\n",
      "fundamental_14 :  6.8232319373e-75\n",
      "fundamental_15 :  -1.78399085607e-76\n",
      "fundamental_16 :  1.02871276072e-76\n",
      "fundamental_17 :  3.65881442347e-62\n",
      "fundamental_18 :  6.0172080221e-76\n",
      "fundamental_19 :  -3.82617813835e-77\n",
      "fundamental_20 :  -8.57868114968e-76\n",
      "fundamental_21 :  -5.28136739657e-77\n",
      "fundamental_22 :  8.42783304228e-77\n",
      "fundamental_23 :  1.20469180215e-74\n",
      "fundamental_24 :  3.13514219491e-77\n",
      "fundamental_25 :  1.16453861399e-76\n",
      "fundamental_26 :  2.43769147405e-73\n",
      "fundamental_27 :  8.89930829896e-76\n",
      "fundamental_28 :  4.0486422861e-77\n",
      "fundamental_29 :  -2.44304297442e-76\n",
      "fundamental_30 :  -3.34931032221e-76\n",
      "fundamental_31 :  2.00797257683e-77\n",
      "fundamental_32 :  7.58001305723e-75\n",
      "fundamental_33 :  4.92903215907e-73\n",
      "fundamental_34 :  2.84306965814e-75\n",
      "fundamental_35 :  1.02293118798e-76\n",
      "fundamental_36 :  1.10332088247e-74\n",
      "fundamental_37 :  9.2639630965e-77\n",
      "fundamental_38 :  7.83254997945e-78\n",
      "fundamental_39 :  1.41897915584e-76\n",
      "fundamental_40 :  5.02498605665e-77\n",
      "fundamental_41 :  1.14423782558e-72\n",
      "fundamental_42 :  1.07412453883e-72\n",
      "fundamental_43 :  -7.08078602652e-77\n",
      "fundamental_44 :  -6.70372137047e-77\n",
      "fundamental_45 :  8.0073689736e-76\n",
      "fundamental_46 :  -2.51799621622e-78\n",
      "fundamental_47 :  1.47207511378e-76\n",
      "fundamental_48 :  2.85748328959e-76\n",
      "fundamental_49 :  4.84796808456e-77\n",
      "fundamental_50 :  5.95891885815e-75\n",
      "fundamental_51 :  8.01830506462e-76\n",
      "fundamental_52 :  1.08558406606e-76\n",
      "fundamental_53 :  1.31883512755e-76\n",
      "fundamental_54 :  -3.83755942746e-77\n",
      "fundamental_55 :  3.22598007121e-76\n",
      "fundamental_56 :  2.03726956276e-76\n",
      "fundamental_57 :  5.54634117613e-77\n",
      "fundamental_58 :  5.38880879151e-77\n",
      "fundamental_59 :  -5.6911830453e-77\n",
      "fundamental_60 :  -3.03908432586e-76\n",
      "fundamental_61 :  1.52351588532e-63\n",
      "fundamental_62 :  2.8604918048e-77\n",
      "fundamental_63 :  1.62442255816e-77\n",
      "technical_0 :  1.68398177829e-76\n",
      "technical_1 :  8.85797534138e-78\n",
      "technical_2 :  -9.61700339532e-79\n",
      "technical_3 :  -1.65548614206e-77\n",
      "technical_5 :  -6.2335729901e-77\n",
      "technical_6 :  3.40402927455e-78\n",
      "technical_7 :  -9.21455886203e-77\n",
      "technical_9 :  -2.37683335778e-41\n",
      "technical_10 :  -1.29888674815e-77\n",
      "technical_11 :  6.1625918177e-78\n",
      "technical_12 :  -5.94267662401e-77\n",
      "technical_13 :  2.24976925054e-77\n",
      "technical_14 :  1.77966444998e-77\n",
      "technical_16 :  9.73528405871e-79\n",
      "technical_17 :  1.17977505092e-77\n",
      "technical_18 :  -2.53413913884e-66\n",
      "technical_19 :  -9.61680754507e-78\n",
      "technical_20 :  -7.09315167325e-77\n",
      "technical_21 :  2.70171863673e-77\n",
      "technical_22 :  -4.22366597822e-77\n",
      "technical_24 :  -5.82765174662e-78\n",
      "technical_25 :  7.17757808749e-79\n",
      "technical_27 :  -2.76579441856e-77\n",
      "technical_28 :  3.71641320108e-77\n",
      "technical_29 :  3.47350308837e-77\n",
      "technical_30 :  -7.77804572481e-77\n",
      "technical_31 :  -3.19273840373e-77\n",
      "technical_32 :  -8.62735308701e-75\n",
      "technical_33 :  -3.9232026425e-78\n",
      "technical_34 :  2.84495858918e-77\n",
      "technical_35 :  3.03846549314e-78\n",
      "technical_36 :  -7.09929761557e-78\n",
      "technical_37 :  1.07589071642e-75\n",
      "technical_38 :  -8.82671204002e-75\n",
      "technical_39 :  -3.90139019677e-74\n",
      "technical_40 :  -1.78044554479e-77\n",
      "technical_41 :  -2.33499675075e-77\n",
      "technical_42 :  1.47409742348e-66\n",
      "technical_43 :  5.83975457476e-78\n",
      "technical_44 :  4.55952154453e-77\n",
      "-0.00280080863346\n"
     ]
    }
   ],
   "source": [
    "# A cell to perform local E2E training and prediction that simulates\n",
    "# the KaggleGym behavior.\n",
    "def localE2E(run_validation=True, visualize_model=False):\n",
    "    \"\"\"A function to simulate KaggleGym behavior of predicting per timestep.\n",
    "    \"\"\"\n",
    "    # Here's an example of loading the CSV using Pandas's built-in HDF5 support:\n",
    "    with pd.HDFStore(\"train.h5\", \"r\") as train:\n",
    "        # Note that the \"train\" dataframe is the only dataframe in the file\n",
    "        df = train.get(\"train\")\n",
    "        train_df = df[:806298]\n",
    "        valid_df = df[806298:]\n",
    "    \n",
    "    # NOTE: Training goes here.\n",
    "    model = train_model(train_df)\n",
    "    if visualize_model:\n",
    "        model.visualize()\n",
    "    \n",
    "    if not run_validation:\n",
    "        return 0\n",
    "    \n",
    "    # Validation goes here.\n",
    "    predictions = []\n",
    "    curr_timestamp = 0\n",
    "    curr_data = []\n",
    "    curr_target = []\n",
    "    for row in valid_df.itertuples():\n",
    "        # If it is a new timestamp, predict.\n",
    "        if row.timestamp != curr_timestamp:\n",
    "            if curr_data:\n",
    "                # NOTE: Inference and updating goes here.\n",
    "                new_targets = run_infer(\n",
    "                    model,\n",
    "                    # Drop the last column (y).\n",
    "                    pd.DataFrame(curr_data, columns=valid_df.columns[:-1]),\n",
    "                    pd.DataFrame(curr_target, columns=['id', 'y']))\n",
    "                predictions.extend(list(new_targets['y']))\n",
    "            # Reset arrays.\n",
    "            curr_data = []\n",
    "            curr_target= []\n",
    "            curr_timestamp = row.timestamp\n",
    "        # Drop the first (index) and last (y) into features.\n",
    "        curr_data.append(list(row)[1:-1])\n",
    "        curr_target.append([row.id, 0])\n",
    "\n",
    "    # Infer for the last timestamp.\n",
    "    new_targets = run_infer(\n",
    "        model,\n",
    "        # Drop the last column (y).\n",
    "        pd.DataFrame(curr_data, columns=valid_df.columns[:-1]),\n",
    "        pd.DataFrame(curr_target, columns=['id', 'y']))\n",
    "\n",
    "    predictions.extend(list(new_targets['y']))\n",
    "    return evaluate(valid_df['y'], predictions)\n",
    "\n",
    "print(localE2E(run_validation=True, visualize_model=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data from Kagglegym\n",
    "import kagglegym\n",
    "\n",
    "def kaggleE2E():\n",
    "    \"\"\"Runs Kaggle training and predictions E2E.\n",
    "    \"\"\"\n",
    "    # Create env.\n",
    "    env = kagglegym.make()\n",
    "    # Get first observation.\n",
    "    observation = env.reset()\n",
    "    # Get train data.\n",
    "    train_df = observation.train\n",
    "    model = train_model(train_df)\n",
    "\n",
    "    # Predict using Kagglegym.\n",
    "    while True:\n",
    "        predictions = run_infer(model, observation.features, observation.target)\n",
    "        observation, reward, done, info = env.step(predictions)\n",
    "        # print('Reward: ', reward)\n",
    "        if done:\n",
    "            break\n",
    "    print(info)\n",
    "\n",
    "kaggleE2E()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
