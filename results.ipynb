{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical features only\n",
    "\n",
    "### After examining the results, it looks like most of the fundamental and derived features have very weird distributions. So, lets focus on technical features first.\n",
    "\n",
    "All results are based on\n",
    "- #### only technical features given\n",
    "- learnt ignoring the id field\n",
    "- not in an online way (i.e. prediction doesn't update the training model)\n",
    "\n",
    "| R train  | R valid  | Model                                               | Normalization | Imputation |\n",
    "|----------|----------|-----------------------------------------------------|---------------|------------|\n",
    "| 0.0255   |0.007537  | LinearRegression                                    |      SS       |   Mean     |\n",
    "| 0.025606 |0.007966  | LinearRegression                                    |      SS       |  Median    |\n",
    "| 0.001439 |-0.00279  | LinearRegression                                    |      RS       |   Mean     |\n",
    "| 0.001702 |-0.00283  | LinearRegression                                    |      RS       |  Median    |\n",
    "| -1.99220 |-2.00206  | RANSACRegressor                                     |      SS       |   Mean     |\n",
    "| -2.04748 |-2.25799  | RANSACRegressor                                     |      SS       |  Median    |\n",
    "| -0.01047 |-0.02664  | HuberRegressor                                      |      SS       |  Median    |\n",
    "| 0.000307 |-0.00285  | Lasso (a = 1)                                       |      SS       |  Median    |\n",
    "| 0.021038 |0.017875  | Lasso (a = 1e-4)                                    |      SS       |  Median    |\n",
    "| 0.025340 |0.014118  | Lasso (a = 1e-5)                                    |      SS       |  Median    |\n",
    "| 0.025606 |0.007966  | Ridge (a = 1)                                       |      SS       |  Median    |\n",
    "| 0.025606 |0.007966  | Ridge (a = 1e-3)                                    |      SS       |  Median    |\n",
    "| 0.025603 |0.009000  | BayesianRidge (default)                             |      SS       |  Median    |\n",
    "\n",
    "Normalization:\n",
    "- SS: StandardScaler\n",
    "- RS: RobustScaler\n",
    "\n",
    "## Notes\n",
    "- RANSACRegressor performs very badly, essentially, there are a lot of predictions that goes beyond the 'expected'\n",
    "  bound from the previous y values.\n",
    "- Lasso at alpha = 1 and alpha = 0.01 actually kills off all the features... hmm.\n",
    "- Ridge is almost useless since the weight is probably too small anyway to be affected by regularization.\n",
    "\n",
    "### So far, seems like Lasso performs the best, followed by LinearRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Results\n",
    "\n",
    "### LinearRegressor seems to perform the best, followed by RANSACRegressor. The rest are not even close.\n",
    "\n",
    "Results for sklearn.linear_model.\n",
    "\n",
    "All results are based on\n",
    "- all features given\n",
    "- learnt ignoring the id field\n",
    "- not in an online way (i.e. prediction doesn't update the training model)\n",
    "- using median value for imputation\n",
    "- using RobustScaler for normalizing features.\n",
    "\n",
    "|R value   | Model                                               | \n",
    "|----------|-----------------------------------------------------|\n",
    "|-0.002833 | Linear regression                                   |\n",
    "|-0.348907 | Ridge (a = 1)                                       |\n",
    "|-0.348906 | Ridge (a = 0.01)                                    |\n",
    "|-0.348906 | Ridge (a = 0.001)                                   |\n",
    "|-0.016866 | Lasso (a = 1)                                       |\n",
    "|-0.034226 | Lasso (a = 0.01)                                    |\n",
    "|-0.047910 | Lasso (a = 0.001)                                   |\n",
    "|-0.193901 | OrthogonalMatchingPursuit (default)                 |\n",
    "|-0.025288 | BayesianRidge (default)                             |\n",
    "|-9.652e82 | SGDRegressor (sq_loss, l2, default)                 |\n",
    "|-8.153e82 | SGDRegressor (sq_loss, elasticnet, default)         |\n",
    "|-1.603e83 | SGDRegressor (sq_loss, l1, default)                 |\n",
    "|-6.465e69 | SGDRegressor (huber, l1, default)                   |\n",
    "|-0.008357 | PassiveAggressiveRegressor (default)                |\n",
    "|-0.008184 | HuberRegressor (default)                            |\n",
    "|-0.002871 | RANSACRegressor (default)                           |\n",
    "\n",
    "\n",
    "## Details\n",
    "- Adding regularization (Ridge, Lasso, OMP etc) seem to hurt R value in general.\n",
    "- Lasso training takes really long.\n",
    "- Lasso at alpha = 1 was able to get pretty decent results even though it only selects about\n",
    "~10 features with nonnegative weight.\n",
    "- ARDRegression kept crashing the notebook, so we didn't ended up trying it.\n",
    "- SGDRegressor has very high error and feature weights.\n",
    "- RANSACRegressor actually performs pretty well, making it the second best.\n",
    "\n",
    "### Notes: LinearRegression actually performs badly on the testing set (score of -0.853...), while RANSACRegressor gets score < -1.00 ...\n",
    "Looking at distribution of the LinearRegression's predictions is concerning where most of the values are between .000249 and 0.000519, which is very different from the original y distribution of -0.0860941 to 0.0934978."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression Results\n",
    "#### In general, LinearRegression does not perform very well, with only about -0.002833 for the best result\n",
    "\n",
    "All results are based on\n",
    "- all features given\n",
    "- learnt ignoring the id field\n",
    "- not in an online way (i.e. prediction doesn't update the training model)\n",
    "\n",
    "|R value   | Model            | Normalization | Missing |\n",
    "|----------|------------------|---------------|---------|\n",
    "|-0.008351 | Always set to 0  |               |         |\n",
    "|-0.005666 | Linear regression| None          |    0    |\n",
    "|-0.074787 | Linear regression| None          |  mean   |\n",
    "|-0.060731 | Linear regression| None          | median  |\n",
    "|-0.293456 | Linear regression| normalize=true|    0    |\n",
    "|-0.329960 | Linear regression| normalize=true|  mean   |\n",
    "|-0.002833 | Linear regression| RS            |    0    |\n",
    "|-0.005737 | Linear regression| RS            |  mean   |\n",
    "|-0.002833 | Linear regression| RS            | median  |\n",
    "|-0.345930 | Linear regression| SS            |    0    |\n",
    "|-0.329960 | Linear regression| SS            |  mean   |\n",
    "|-0.348907 | Linear regression| SS            | median  |\n",
    "|-0.345930 | Linear regression| MAS           |    0    |\n",
    "|-0.329960 | Linear regression| MAS           |  mean   |\n",
    "|-0.348907 | Linear regression| MAS           | median  |\n",
    "\n",
    "\n",
    "Column descriptions:\n",
    "- Normalization: Whether we perform normalization on the feature values.\n",
    "  - RS: RobustScaler\n",
    "  - SS: StandardScaler\n",
    "  - MAS: MaxAbsScaler\n",
    "- Features: The features used by model.\n",
    "- Id: Whether we use the id to train a different model per row.\n",
    "- Online: Whether we use the eval data to update the model param.\n",
    "- Missing: What value do we replace with the missing value.\n",
    "\n",
    "## Details\n",
    "\n",
    "A dumb method of setting everything to 0 actually perform relatively well...\n",
    "\n",
    "For Linear regression without any normalization, the coefficient for each feature is very low (around e^-20 - e^-30), probably because the features are not normalized and thus too high. It also seems like one of the weight (derived_3) is 0. Hypothesis is that derived_features is computed from fundamental features.\n",
    "\n",
    "Trying a bunch of imputation for NaN and normalization techniques.\n",
    "\n",
    "Normalization:\n",
    "- Not doing any normalization actually perform relatively well, especially since it is a linear regression. Only RobustScaler performs better.\n",
    "- normalize=True for LinearRegression model seems to perform a lot worse than not doing normalization (most likely it is a StandardScaler)\n",
    "- RobustScaler performs relatively well.\n",
    "- StandardScaler and MaxAbsScaler performs badly.\n",
    "\n",
    "Imputation:\n",
    "- Missing value = 0 is actually fairly good.\n",
    "- Missing value = \"most frequent\" needs a really long time for training, not sure why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
